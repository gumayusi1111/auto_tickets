#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
page_crawler.py
é¡µé¢çˆ¬å–æ¨¡å—
"""

import json
import time
import os
from datetime import datetime
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from typing import Dict, Any, Optional


class PageCrawler:
    """é¡µé¢å†…å®¹çˆ¬å–å™¨"""
    
    def __init__(self, driver):
        self.driver = driver
        self.page_data = {
            'timestamp': datetime.now().isoformat(),
            'crawl_timestamp': datetime.now().isoformat(),
            'url': '',
            'page_title': '',
            'html_content': '',
            'page_crawl_success': False,
            'form_elements': {
                'input_fields': [],
                'checkboxes': [],
                'radio_buttons': [],
                'select_dropdowns': [],
                'textareas': [],
                'buttons': []
            }
        }
    
    def crawl_page_content(self, timeout=10):
        """çˆ¬å–å½“å‰é¡µé¢çš„æ‰€æœ‰å†…å®¹
        
        åŒ…å«:
        1. å®Œæ•´çš„HTMLæºç 
        2. é¡µé¢æ ‡é¢˜å’ŒURL
        3. æ‰€æœ‰è¡¨å•å…ƒç´ ï¼ˆè¾“å…¥æ¡†ã€å¤é€‰æ¡†ã€æŒ‰é’®ç­‰ï¼‰
        4. ä½¿ç”¨å¤šç§æ–¹æ³•ç¡®ä¿å…ƒç´ è·å–å®Œæ•´
        """
        print("\nğŸ“„ å¼€å§‹çˆ¬å–è·³è½¬åé¡µé¢çš„å®Œæ•´å†…å®¹...")
        
        try:
            # æ™ºèƒ½ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.webdriver.common.by import By
            from selenium.common.exceptions import TimeoutException
            
            try:
                # ç­‰å¾…é¡µé¢DOMåŠ è½½å®Œæˆ
                WebDriverWait(self.driver, 5).until(
                    lambda d: d.execute_script("return document.readyState") == "complete"
                )
                print("âœ… é¡µé¢DOMåŠ è½½å®Œæˆ")
            except TimeoutException:
                print("âš ï¸ é¡µé¢DOMåŠ è½½è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ")
                time.sleep(1)  # å¤‡ç”¨ç­‰å¾…
            
            # è·å–åŸºæœ¬é¡µé¢ä¿¡æ¯
            self.page_data['url'] = self.driver.current_url
            self.page_data['page_title'] = self.driver.title
            print(f"ğŸ“ é¡µé¢URL: {self.page_data['url']}")
            print(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {self.page_data['page_title']}")
            
            # è·å–å®Œæ•´çš„HTMLæºç 
            print("ğŸ•·ï¸ è·å–å®Œæ•´HTMLå†…å®¹...")
            self.page_data['html_content'] = self.driver.page_source
            html_size = len(self.page_data['html_content'])
            print(f"ğŸ“ HTMLå†…å®¹å¤§å°: {html_size} å­—ç¬¦")
            
            # çˆ¬å–æ‰€æœ‰è¡¨å•å…ƒç´ 
            print("ğŸ” å¼€å§‹çˆ¬å–è¡¨å•å…ƒç´ ...")
            self._crawl_form_elements()
            
            # ç»Ÿè®¡çˆ¬å–ç»“æœ
            form_elements = self.page_data['form_elements']
            total_elements = (
                len(form_elements['input_fields']) +
                len(form_elements['checkboxes']) +
                len(form_elements['radio_buttons']) +
                len(form_elements['select_dropdowns']) +
                len(form_elements['textareas']) +
                len(form_elements['buttons'])
            )
            
            print(f"ğŸ“Š è¡¨å•å…ƒç´ ç»Ÿè®¡:")
            print(f"   ğŸ“ è¾“å…¥æ¡†: {len(form_elements['input_fields'])} ä¸ª")
            print(f"   â˜‘ï¸ å¤é€‰æ¡†: {len(form_elements['checkboxes'])} ä¸ª")
            print(f"   ğŸ”˜ å•é€‰æ¡†: {len(form_elements['radio_buttons'])} ä¸ª")
            print(f"   ğŸ“‹ ä¸‹æ‹‰æ¡†: {len(form_elements['select_dropdowns'])} ä¸ª")
            print(f"   ğŸ“„ æ–‡æœ¬åŸŸ: {len(form_elements['textareas'])} ä¸ª")
            print(f"   ğŸ”² æŒ‰é’®: {len(form_elements['buttons'])} ä¸ª")
            print(f"   ğŸ“Š æ€»è®¡: {total_elements} ä¸ªè¡¨å•å…ƒç´ ")
            
            # æ ‡è®°çˆ¬å–æˆåŠŸ
            self.page_data['page_crawl_success'] = True
            
            print("âœ… é¡µé¢å†…å®¹çˆ¬å–å®Œæˆ")
            return self.page_data
            
        except Exception as e:
            print(f"âŒ çˆ¬å–é¡µé¢å†…å®¹å¤±è´¥: {e}")
            self.page_data['page_crawl_success'] = False
            return self.page_data
    
    def _crawl_form_elements(self):
        """çˆ¬å–æ‰€æœ‰è¡¨å•å…ƒç´ """
        print("ğŸ” æ­£åœ¨çˆ¬å–è¡¨å•å…ƒç´ ...")
        
        # æ–¹æ³•1: é€šè¿‡æ ‡ç­¾åæŸ¥æ‰¾
        self._crawl_by_tag_names()
        
        # æ–¹æ³•2: é€šè¿‡å¸¸è§çš„CSSé€‰æ‹©å™¨æŸ¥æ‰¾
        self._crawl_by_css_selectors()
        
        # æ–¹æ³•3: é€šè¿‡XPathæŸ¥æ‰¾
        self._crawl_by_xpath()
        
        # å»é‡å’Œæ•´ç†æ•°æ®
        self._deduplicate_elements()
    
    def _crawl_by_tag_names(self):
        """æ–¹æ³•1: é€šè¿‡HTMLæ ‡ç­¾åçˆ¬å–å…ƒç´ """
        try:
            # è¾“å…¥æ¡†
            inputs = self.driver.find_elements(By.TAG_NAME, "input")
            for input_elem in inputs:
                element_data = self._extract_element_data(input_elem)
                if element_data['type'] == 'checkbox':
                    self.page_data['form_elements']['checkboxes'].append(element_data)
                elif element_data['type'] == 'radio':
                    self.page_data['form_elements']['radio_buttons'].append(element_data)
                else:
                    self.page_data['form_elements']['input_fields'].append(element_data)
            
            # ä¸‹æ‹‰é€‰æ‹©æ¡†
            selects = self.driver.find_elements(By.TAG_NAME, "select")
            for select_elem in selects:
                element_data = self._extract_element_data(select_elem)
                self.page_data['form_elements']['select_dropdowns'].append(element_data)
            
            # æ–‡æœ¬åŸŸ
            textareas = self.driver.find_elements(By.TAG_NAME, "textarea")
            for textarea_elem in textareas:
                element_data = self._extract_element_data(textarea_elem)
                self.page_data['form_elements']['textareas'].append(element_data)
            
            # æŒ‰é’®
            buttons = self.driver.find_elements(By.TAG_NAME, "button")
            for button_elem in buttons:
                element_data = self._extract_element_data(button_elem)
                self.page_data['form_elements']['buttons'].append(element_data)
                
        except Exception as e:
            print(f"âš ï¸ æ ‡ç­¾åæ–¹æ³•çˆ¬å–å¤±è´¥: {e}")
    
    def _crawl_by_css_selectors(self):
        """æ–¹æ³•2: é€šè¿‡CSSé€‰æ‹©å™¨çˆ¬å–å…ƒç´ """
        try:
            # å¸¸è§çš„è¡¨å•é€‰æ‹©å™¨
            selectors = [
                'input[type="text"]',
                'input[type="email"]',
                'input[type="tel"]',
                'input[type="date"]',
                'input[type="number"]',
                'input[type="password"]',
                'input[type="checkbox"]',
                'input[type="radio"]',
                'input[type="submit"]',
                'input[type="button"]',
                'button[type="submit"]',
                'button[class*="submit"]',
                'button[class*="confirm"]',
                '.form-control',
                '.form-input',
                '.checkbox',
                '.radio'
            ]
            
            for selector in selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        element_data = self._extract_element_data(elem)
                        element_data['found_by'] = f'css: {selector}'
                        
                        # æ ¹æ®ç±»å‹åˆ†ç±»
                        if 'checkbox' in selector or element_data['type'] == 'checkbox':
                            self.page_data['form_elements']['checkboxes'].append(element_data)
                        elif 'radio' in selector or element_data['type'] == 'radio':
                            self.page_data['form_elements']['radio_buttons'].append(element_data)
                        elif 'submit' in selector or 'button' in selector:
                            self.page_data['form_elements']['buttons'].append(element_data)
                        else:
                            self.page_data['form_elements']['input_fields'].append(element_data)
                            
                except Exception:
                    continue
                    
        except Exception as e:
            print(f"âš ï¸ CSSé€‰æ‹©å™¨æ–¹æ³•çˆ¬å–å¤±è´¥: {e}")
    
    def _crawl_by_xpath(self):
        """æ–¹æ³•3: é€šè¿‡XPathçˆ¬å–å…ƒç´ """
        try:
            # å¸¸è§çš„XPathè¡¨è¾¾å¼
            xpaths = [
                "//input[@type='text' or @type='email' or @type='tel' or @type='date']",
                "//input[@type='checkbox']",
                "//input[@type='radio']",
                "//button[contains(text(), 'ì œì¶œ') or contains(text(), 'í™•ì¸') or contains(text(), 'ì‹ ì²­')]",
                "//button[contains(@class, 'submit') or contains(@class, 'confirm')]",
                "//input[contains(@placeholder, 'ìƒë…„ì›”ì¼') or contains(@placeholder, 'ì „í™”ë²ˆí˜¸')]",
                "//input[contains(@name, 'birth') or contains(@name, 'phone') or contains(@name, 'mobile')]",
                "//textarea",
                "//select"
            ]
            
            for xpath in xpaths:
                try:
                    elements = self.driver.find_elements(By.XPATH, xpath)
                    for elem in elements:
                        element_data = self._extract_element_data(elem)
                        element_data['found_by'] = f'xpath: {xpath}'
                        
                        # æ ¹æ®XPathç‰¹å¾åˆ†ç±»
                        if 'checkbox' in xpath:
                            self.page_data['form_elements']['checkboxes'].append(element_data)
                        elif 'radio' in xpath:
                            self.page_data['form_elements']['radio_buttons'].append(element_data)
                        elif 'button' in xpath:
                            self.page_data['form_elements']['buttons'].append(element_data)
                        elif 'textarea' in xpath:
                            self.page_data['form_elements']['textareas'].append(element_data)
                        elif 'select' in xpath:
                            self.page_data['form_elements']['select_dropdowns'].append(element_data)
                        else:
                            self.page_data['form_elements']['input_fields'].append(element_data)
                            
                except Exception:
                    continue
                    
        except Exception as e:
            print(f"âš ï¸ XPathæ–¹æ³•çˆ¬å–å¤±è´¥: {e}")
    
    def _extract_element_data(self, element):
        """æå–å…ƒç´ çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            return {
                'tag_name': element.tag_name,
                'type': element.get_attribute('type') or '',
                'name': element.get_attribute('name') or '',
                'id': element.get_attribute('id') or '',
                'class': element.get_attribute('class') or '',
                'placeholder': element.get_attribute('placeholder') or '',
                'value': element.get_attribute('value') or '',
                'text': element.text or '',
                'required': element.get_attribute('required') is not None,
                'disabled': element.get_attribute('disabled') is not None,
                'visible': element.is_displayed(),
                'enabled': element.is_enabled(),
                'location': element.location,
                'size': element.size,
                'found_by': 'tag_name'
            }
        except Exception as e:
            return {
                'error': str(e),
                'tag_name': 'unknown',
                'found_by': 'error'
            }
    
    def _deduplicate_elements(self):
        """å»é™¤é‡å¤çš„å…ƒç´ """
        for category in self.page_data['form_elements']:
            elements = self.page_data['form_elements'][category]
            unique_elements = []
            seen_elements = set()
            
            for elem in elements:
                # åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦
                identifier = f"{elem.get('tag_name', '')}_{elem.get('type', '')}_{elem.get('name', '')}_{elem.get('id', '')}"
                if identifier not in seen_elements:
                    seen_elements.add(identifier)
                    unique_elements.append(elem)
            
            self.page_data['form_elements'][category] = unique_elements
    
    def save_page_data(self, filename=None):
        """ä¿å­˜é¡µé¢æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            if not filename:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"page_crawl_{timestamp}.json"
            
            # ç¡®ä¿dataç›®å½•å­˜åœ¨
            data_dir = "/Users/wenbai/Desktop/chajian/auto/data"
            os.makedirs(data_dir, exist_ok=True)
            
            filepath = os.path.join(data_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.page_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“ é¡µé¢æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¿å­˜é¡µé¢æ•°æ®å¤±è´¥: {e}")
            return None
    
    def print_summary(self):
        """æ‰“å°çˆ¬å–ç»“æœæ‘˜è¦"""
        print("\nğŸ“Š é¡µé¢çˆ¬å–ç»“æœæ‘˜è¦:")
        print(f"ğŸ“ URL: {self.page_data['url']}")
        
        for category, elements in self.page_data['form_elements'].items():
            if elements:
                print(f"ğŸ”¹ {category}: {len(elements)} ä¸ª")
                for elem in elements[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    name = elem.get('name', '') or elem.get('id', '') or elem.get('placeholder', '')
                    print(f"   - {elem.get('tag_name', 'unknown')} ({elem.get('type', 'unknown')}): {name}")
                if len(elements) > 3:
                    print(f"   ... è¿˜æœ‰ {len(elements) - 3} ä¸ª")

def crawl_page_content(driver) -> Dict[str, Any]:
    """
    çˆ¬å–é¡µé¢å†…å®¹
    
    Args:
        driver: WebDriverå®ä¾‹
    
    Returns:
        é¡µé¢å†…å®¹æ•°æ®
    """
    try:
        # è·å–åŸºæœ¬é¡µé¢ä¿¡æ¯
        page_data = {
            'html_content': driver.page_source,
            'page_crawl_success': True,
            'crawl_timestamp': datetime.now().isoformat(),
            'page_title': driver.title,
            'page_url': driver.current_url
        }
        
        # è·å–HTMLå†…å®¹å¤§å°
        html_size = len(page_data['html_content'])
        print(f"ğŸ“ HTMLå†…å®¹å¤§å°: {html_size} å­—ç¬¦")
        
        return page_data
        
    except Exception as e:
        print(f"âŒ é¡µé¢å†…å®¹çˆ¬å–å¤±è´¥: {e}")
        return {
            'html_content': '',
            'page_crawl_success': False,
            'crawl_timestamp': datetime.now().isoformat(),
            'page_title': '',
            'page_url': driver.current_url,
            'error': str(e)
        }