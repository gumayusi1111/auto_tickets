#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_correct_click_crawl.py
æ­£ç¡®çš„ç‚¹å‡»åçˆ¬å–æµ‹è¯• - åªåœ¨ç‚¹å‡»æŒ‰é’®åç›‘æ§è¯·æ±‚
"""

import sys
import os
import json
import time
import requests
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import threading

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.weverse.browser.setup import setup_driver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities


def calculate_optimized_advance_time(ping_latency_ms: float) -> float:
    """
    åŸºäºå®é™…pingå»¶è¿Ÿä¼˜åŒ–è®¡ç®—æå‰æ—¶é—´
    
    Args:
        ping_latency_ms: å®é™…pingå»¶è¿Ÿ(æ¯«ç§’)
    
    Returns:
        ä¼˜åŒ–åçš„æå‰æ—¶é—´(æ¯«ç§’)
    """
    print(f"ğŸ¯ åŸºäºä½ çš„pingå»¶è¿Ÿä¼˜åŒ–è®¡ç®—: {ping_latency_ms}ms")
    
    # ç†è®ºæœ€ä½å»¶è¿Ÿ = pingå»¶è¿Ÿ
    base_latency = ping_latency_ms
    
    # æµè§ˆå™¨å¤„ç†å¼€é”€ (ç‚¹å‡»->å‘é€è¯·æ±‚)
    browser_overhead = 50  # 50msæ˜¯åˆç†çš„æµè§ˆå™¨å¤„ç†æ—¶é—´
    
    # ç½‘ç»œæ³¢åŠ¨ç¼“å†² (ä¿å®ˆä¼°è®¡)
    network_buffer = ping_latency_ms * 0.1  # pingå»¶è¿Ÿçš„10%ä½œä¸ºæ³¢åŠ¨ç¼“å†²
    
    # å®‰å…¨è¾¹è· (æœ€å°50ms)
    safety_margin = max(50, ping_latency_ms * 0.05)  # pingå»¶è¿Ÿçš„5%æˆ–50ms
    
    # è®¡ç®—æ€»æå‰æ—¶é—´
    total_advance = base_latency + browser_overhead + network_buffer + safety_margin
    
    print(f"ğŸ“Š å»¶è¿Ÿåˆ†è§£:")
    print(f"   ğŸŒ åŸºç¡€ç½‘ç»œå»¶è¿Ÿ: {base_latency:.1f}ms")
    print(f"   ğŸ–¥ï¸ æµè§ˆå™¨å¤„ç†å¼€é”€: {browser_overhead:.1f}ms")  
    print(f"   ğŸ“Š ç½‘ç»œæ³¢åŠ¨ç¼“å†²: {network_buffer:.1f}ms")
    print(f"   ğŸ›¡ï¸ å®‰å…¨è¾¹è·: {safety_margin:.1f}ms")
    print(f"   âš¡ æ€»è®¡æå‰æ—¶é—´: {total_advance:.1f}ms")
    
    return total_advance


def test_real_ping_latency() -> float:
    """æµ‹è¯•çœŸå®çš„HTTPå»¶è¿Ÿï¼ˆæ¨¡æ‹Ÿpingï¼‰"""
    print("ğŸŒ æµ‹è¯•çœŸå®HTTPå»¶è¿Ÿ...")
    
    latencies = []
    test_count = 10
    
    for i in range(test_count):
        try:
            start_time = time.perf_counter()
            response = requests.head(
                "https://weverse.io", 
                timeout=5,
                headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
            )
            end_time = time.perf_counter()
            
            latency_ms = (end_time - start_time) * 1000
            latencies.append(latency_ms)
            
            print(f"\rğŸ“¡ æµ‹è¯• {i+1}/{test_count}: {latency_ms:.1f}ms", end="", flush=True)
            time.sleep(0.5)
            
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
    
    if latencies:
        avg_latency = sum(latencies) / len(latencies)
        min_latency = min(latencies)
        max_latency = max(latencies)
        
        print(f"\nğŸ“Š HTTPå»¶è¿Ÿæµ‹è¯•ç»“æœ:")
        print(f"   å¹³å‡: {avg_latency:.1f}ms")
        print(f"   æœ€å¿«: {min_latency:.1f}ms") 
        print(f"   æœ€æ…¢: {max_latency:.1f}ms")
        
        return avg_latency
    else:
        print("\nâš ï¸ HTTPå»¶è¿Ÿæµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨ä½ æä¾›çš„770ms")
        return 770.0


class ClickThenCrawlMonitor:
    """ç‚¹å‡»åçˆ¬å–ç›‘æ§å™¨"""
    
    def __init__(self, driver):
        self.driver = driver
        self.monitoring = False
        self.requests_data = []
        self.monitor_thread = None
        
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§ç½‘ç»œè¯·æ±‚"""
        print("ğŸš€ å¼€å§‹ç›‘æ§ç½‘ç»œè¯·æ±‚...")
        self.monitoring = True
        self.requests_data = []
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitor_thread = threading.Thread(target=self._monitor_requests)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
    def _monitor_requests(self):
        """ç›‘æ§ç½‘ç»œè¯·æ±‚çš„çº¿ç¨‹å‡½æ•°"""
        while self.monitoring:
            try:
                # è·å–æ€§èƒ½æ—¥å¿—
                logs = self.driver.get_log('performance')
                
                for log in logs:
                    message = json.loads(log['message'])
                    
                    # æ•è·ç½‘ç»œå“åº”
                    if message['message']['method'] == 'Network.responseReceived':
                        response = message['message']['params']['response']
                        request_data = {
                            'url': response['url'],
                            'status': response['status'],
                            'method': response.get('method', 'GET'),
                            'headers': dict(response.get('headers', {})),
                            'timestamp': datetime.now().isoformat(),
                            'timing': response.get('timing', {})
                        }
                        self.requests_data.append(request_data)
                        
                        # å®æ—¶æ˜¾ç¤ºé‡è¦è¯·æ±‚
                        if any(keyword in response['url'].lower() for keyword in ['apply', 'submit', 'post', 'api']):
                            print(f"ğŸ¯ é‡è¦è¯·æ±‚: {response['status']} {response['url'][:80]}...")
                
                time.sleep(0.1)  # 100msæ£€æŸ¥é—´éš”
                
            except Exception as e:
                if self.monitoring:  # åªåœ¨è¿˜åœ¨ç›‘æ§æ—¶æŠ¥é”™
                    print(f"âš ï¸ ç›‘æ§å¼‚å¸¸: {e}")
                break
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        print(f"ğŸ›‘ åœæ­¢ç›‘æ§ï¼Œå…±æ•è· {len(self.requests_data)} ä¸ªè¯·æ±‚")
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
        
        return self.requests_data


def test_click_then_crawl():
    """æµ‹è¯•ç‚¹å‡»æŒ‰é’®åçš„çˆ¬å–åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ç‚¹å‡»åçˆ¬å–åŠŸèƒ½")
    print("=" * 50)
    
    # 1. æµ‹è¯•å»¶è¿Ÿå¹¶ä¼˜åŒ–è®¡ç®—
    if input("æ˜¯å¦ä½¿ç”¨ä½ çš„770ms pingå»¶è¿Ÿï¼Ÿ(y/n, é»˜è®¤y): ").lower() != 'n':
        ping_latency = 770.0
    else:
        ping_latency = test_real_ping_latency()
    
    # 2. è®¡ç®—ä¼˜åŒ–çš„æå‰æ—¶é—´
    optimized_advance = calculate_optimized_advance_time(ping_latency)
    
    # 3. è®¾ç½®æµè§ˆå™¨
    print("\nğŸŒ å¯åŠ¨æµè§ˆå™¨...")
    caps = DesiredCapabilities.CHROME
    caps['goog:loggingPrefs'] = {'performance': 'ALL'}
    
    driver = setup_driver(headless=False)
    driver.execute_cdp_cmd('Network.enable', {})
    
    # 4. åˆ›å»ºç›‘æ§å™¨
    monitor = ClickThenCrawlMonitor(driver)
    
    try:
        # 5. è®¿é—®æµ‹è¯•é¡µé¢
        test_url = input("è¯·è¾“å…¥è¦æµ‹è¯•çš„URL (é»˜è®¤: https://weverse.io): ").strip()
        if not test_url:
            test_url = "https://weverse.io"
        
        print(f"ğŸŒ è®¿é—®é¡µé¢: {test_url}")
        driver.get(test_url)
        time.sleep(3)
        
        # 6. æŸ¥æ‰¾å¯ç‚¹å‡»çš„æŒ‰é’®
        print("ğŸ” æŸ¥æ‰¾å¯ç‚¹å‡»çš„æŒ‰é’®...")
        buttons = driver.find_elements(By.TAG_NAME, 'button')
        links = driver.find_elements(By.TAG_NAME, 'a')
        
        clickable_elements = []
        for i, btn in enumerate(buttons[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªæŒ‰é’®
            try:
                if btn.is_displayed() and btn.is_enabled():
                    text = btn.text.strip()[:30] or f"æŒ‰é’®{i+1}"
                    clickable_elements.append((btn, f"æŒ‰é’®: {text}"))
            except:
                pass
        
        for i, link in enumerate(links[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªé“¾æ¥
            try:
                if link.is_displayed():
                    text = link.text.strip()[:30] or f"é“¾æ¥{i+1}"
                    clickable_elements.append((link, f"é“¾æ¥: {text}"))
            except:
                pass
        
        if not clickable_elements:
            print("âŒ æœªæ‰¾åˆ°å¯ç‚¹å‡»çš„å…ƒç´ ")
            return
        
        # 7. æ˜¾ç¤ºå¯ç‚¹å‡»å…ƒç´ ä¾›é€‰æ‹©
        print("\nğŸ–±ï¸ å¯ç‚¹å‡»çš„å…ƒç´ :")
        for i, (element, desc) in enumerate(clickable_elements):
            print(f"   {i+1}. {desc}")
        
        # 8. ç”¨æˆ·é€‰æ‹©è¦ç‚¹å‡»çš„å…ƒç´ 
        try:
            choice = int(input(f"è¯·é€‰æ‹©è¦ç‚¹å‡»çš„å…ƒç´  (1-{len(clickable_elements)}): ")) - 1
            if 0 <= choice < len(clickable_elements):
                target_element, target_desc = clickable_elements[choice]
            else:
                print("âŒ é€‰æ‹©æ— æ•ˆ")
                return
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆ")
            return
        
        # 9. å€’è®¡æ—¶å¹¶ç‚¹å‡»
        print(f"\nâ° å°†åœ¨5ç§’åç‚¹å‡»: {target_desc}")
        print(f"âš¡ ä½¿ç”¨ä¼˜åŒ–çš„æå‰æ—¶é—´: {optimized_advance:.1f}ms")
        
        for i in range(5, 0, -1):
            print(f"\rå€’è®¡æ—¶: {i}ç§’", end="", flush=True)
            time.sleep(1)
        
        print(f"\nğŸ¯ å¼€å§‹ç›‘æ§...")
        
        # 10. ç‚¹å‡»å‰å¼€å§‹ç›‘æ§
        monitor.start_monitoring()
        
        # 11. ç‚¹å‡»å…ƒç´ 
        print(f"ğŸ–±ï¸ ç‚¹å‡»: {target_desc}")
        click_time = datetime.now()
        target_element.click()
        
        # 12. æŒç»­ç›‘æ§
        print("ğŸ“¡ æ­£åœ¨ç›‘æ§ç½‘ç»œè¯·æ±‚...")
        print("æŒ‰ Ctrl+C æˆ–ç­‰å¾…30ç§’ç»“æŸç›‘æ§")
        
        try:
            time.sleep(30)  # ç›‘æ§30ç§’
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç›‘æ§")
        
        # 13. åœæ­¢ç›‘æ§å¹¶ä¿å­˜æ•°æ®
        captured_requests = monitor.stop_monitoring()
        
        # 14. åˆ†æå’Œä¿å­˜ç»“æœ
        result_data = {
            'test_info': {
                'timestamp': datetime.now().isoformat(),
                'target_url': test_url,
                'clicked_element': target_desc,
                'click_time': click_time.isoformat(),
                'ping_latency_ms': ping_latency,
                'optimized_advance_ms': optimized_advance
            },
            'captured_requests': captured_requests,
            'summary': {
                'total_requests': len(captured_requests),
                'important_requests': [
                    req for req in captured_requests 
                    if any(keyword in req['url'].lower() for keyword in ['apply', 'submit', 'post', 'api'])
                ]
            }
        }
        
        # 15. ä¿å­˜æ•°æ®
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"click_crawl_data_{timestamp}.json"
        filepath = project_root / "data" / filename
        filepath.parent.mkdir(exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"   ğŸ–±ï¸ ç‚¹å‡»æ—¶é—´: {click_time.strftime('%H:%M:%S.%f')[:-3]}")
        print(f"   ğŸ“¡ æ•è·è¯·æ±‚: {len(captured_requests)} ä¸ª")
        print(f"   ğŸ¯ é‡è¦è¯·æ±‚: {len(result_data['summary']['important_requests'])} ä¸ª")
        print(f"   ğŸ’¾ æ•°æ®æ–‡ä»¶: {filename}")
        
        # æ˜¾ç¤ºé‡è¦è¯·æ±‚
        if result_data['summary']['important_requests']:
            print(f"\nğŸ¯ é‡è¦è¯·æ±‚åˆ—è¡¨:")
            for req in result_data['summary']['important_requests'][:5]:
                print(f"   {req['status']} {req['method']} {req['url'][:80]}...")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        
    finally:
        monitor.stop_monitoring()
        driver.quit()
        print("âœ… æµè§ˆå™¨å·²å…³é—­")


if __name__ == "__main__":
    test_click_then_crawl() 