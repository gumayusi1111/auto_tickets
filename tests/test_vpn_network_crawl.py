#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_vpn_network_crawl.py
VPNç½‘ç»œå»¶è¿Ÿæ£€æµ‹ã€é¡µé¢çˆ¬å–å’Œè¯·æ±‚ç›‘æ§ç»¼åˆæµ‹è¯•
"""

import sys
import os
import json
import time
import requests
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.weverse.browser.setup import setup_driver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities


def test_vpn_network_latency(duration: int = 15) -> Dict[str, Any]:
    """
    ä¼˜åŒ–çš„VPNç½‘ç»œå»¶è¿Ÿæ£€æµ‹ - ä¸“é—¨é’ˆå¯¹éŸ©å›½WeverseæœåŠ¡å™¨
    """
    print(f"ğŸŒ å¼€å§‹ {duration} ç§’VPNç½‘ç»œå»¶è¿Ÿæ£€æµ‹...")
    
    # æµ‹è¯•ç›®æ ‡ï¼šä½¿ç”¨åŒä¸€åœ°ç†ä½ç½®çš„å¤šä¸ªç«¯ç‚¹
    test_endpoints = [
        "https://www.weverse.io",
        "https://weverse.io",
        "https://api.weverse.io",
        "https://static.weverse.io"
    ]
    
    latencies = []
    successful_tests = 0
    failed_tests = 0
    start_time = time.time()
    
    def single_latency_test(url: str) -> Optional[float]:
        """å•æ¬¡å»¶è¿Ÿæµ‹è¯•"""
        try:
            test_start = time.perf_counter()
            response = requests.head(
                url, 
                timeout=3, 
                allow_redirects=False,
                headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
            )
            test_end = time.perf_counter()
            latency = (test_end - test_start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            return latency
        except:
            return None
    
    print("ğŸ¯ æµ‹è¯•ç«¯ç‚¹:", ", ".join(test_endpoints))
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        while time.time() - start_time < duration:
            # å¯¹æ¯ä¸ªç«¯ç‚¹å¹¶è¡Œæµ‹è¯•
            futures = {
                executor.submit(single_latency_test, url): url 
                for url in test_endpoints
            }
            
            for future in as_completed(futures, timeout=5):
                url = futures[future]
                try:
                    latency_ms = future.result()
                    if latency_ms is not None:
                        latencies.append(latency_ms)
                        successful_tests += 1
                        
                        # å®æ—¶æ˜¾ç¤ºæœ€æ–°ç»“æœ
                        if successful_tests % 8 == 0:
                            recent_avg = sum(latencies[-8:]) / min(8, len(latencies))
                            print(f"\rğŸ“Š æˆåŠŸæµ‹è¯• {successful_tests} æ¬¡, æœ€è¿‘å¹³å‡: {recent_avg:.1f}ms", end="", flush=True)
                    else:
                        failed_tests += 1
                except:
                    failed_tests += 1
            
            time.sleep(0.2)  # é€‚å½“é—´éš”
    
    print()  # æ¢è¡Œ
    
    if not latencies or len(latencies) < 5:
        print("âš ï¸ VPNå»¶è¿Ÿæµ‹è¯•æ•°æ®ä¸è¶³")
        return {
            'avg_ms': 300,
            'min_ms': 150, 
            'max_ms': 800,
            'std_ms': 100,
            'recommended_advance_ms': 400,
            'confidence': 'low',
            'test_count': 0
        }
    
    # æ•°æ®å¤„ç†ï¼šå»é™¤å¼‚å¸¸å€¼
    latencies.sort()
    # å»æ‰æœ€é«˜å’Œæœ€ä½20%çš„å¼‚å¸¸å€¼
    trim_count = max(1, int(len(latencies) * 0.2))
    trimmed_latencies = latencies[trim_count:-trim_count] if len(latencies) > 5 else latencies
    
    stats = {
        'avg_ms': statistics.mean(trimmed_latencies),
        'min_ms': min(trimmed_latencies),
        'max_ms': max(trimmed_latencies),
        'std_ms': statistics.stdev(trimmed_latencies) if len(trimmed_latencies) > 1 else 0,
        'p95_ms': trimmed_latencies[int(len(trimmed_latencies) * 0.95)] if len(trimmed_latencies) > 10 else max(trimmed_latencies),
        'test_count': len(latencies),
        'success_rate': successful_tests / (successful_tests + failed_tests) * 100,
        'confidence': 'high' if len(latencies) >= 20 else 'medium' if len(latencies) >= 10 else 'low'
    }
    
    # åŸºäºä½ æä¾›çš„å®é™…æ•°æ®ä¼˜åŒ–è®¡ç®—
    # ä½ çš„æ•°æ®æ˜¾ç¤ºï¼š36ms-1.32sï¼Œæˆ‘ä»¬éœ€è¦æ›´ä¿å®ˆçš„ç­–ç•¥
    base_advance = stats['avg_ms']
    std_buffer = 2 * stats['std_ms']
    safety_margin = 100  # å¢åŠ å®‰å…¨è¾¹è·åˆ°100ms
    
    # è€ƒè™‘p95å»¶è¿Ÿï¼Œç¡®ä¿95%çš„æƒ…å†µä¸‹éƒ½èƒ½æˆåŠŸ
    p95_buffer = stats['p95_ms'] - stats['avg_ms']
    
    recommended_advance_ms = base_advance + max(std_buffer, p95_buffer) + safety_margin
    
    # æ ¹æ®ä½ çš„å®é™…æ•°æ®ï¼Œé™åˆ¶åœ¨200ms-2000msèŒƒå›´å†…
    stats['recommended_advance_ms'] = max(200, min(2000, recommended_advance_ms))
    
    print(f"ğŸ“Š VPNç½‘ç»œå»¶è¿Ÿæ£€æµ‹ç»“æœ:")
    print(f"   âœ… æˆåŠŸæµ‹è¯•: {stats['test_count']} æ¬¡")
    print(f"   ğŸ“ˆ æˆåŠŸç‡: {stats['success_rate']:.1f}%")
    print(f"   âš¡ å¹³å‡å»¶è¿Ÿ: {stats['avg_ms']:.1f}ms")
    print(f"   ğŸš€ æœ€å¿«å»¶è¿Ÿ: {stats['min_ms']:.1f}ms")
    print(f"   ğŸŒ æœ€æ…¢å»¶è¿Ÿ: {stats['max_ms']:.1f}ms")
    print(f"   ğŸ“Š 95%å»¶è¿Ÿ: {stats['p95_ms']:.1f}ms")
    print(f"   ğŸ“ æ ‡å‡†å·®: {stats['std_ms']:.1f}ms")
    print(f"   âš¡ æ¨èæå‰: {stats['recommended_advance_ms']:.1f}ms")
    print(f"   ğŸ¯ ç½®ä¿¡åº¦: {stats['confidence']}")
    
    return stats


def setup_browser_with_network_monitoring():
    """è®¾ç½®å¸¦ç½‘ç»œç›‘æ§çš„æµè§ˆå™¨"""
    print("ğŸŒ è®¾ç½®æµè§ˆå™¨ç½‘ç»œç›‘æ§...")
    
    # å¯ç”¨æ€§èƒ½æ—¥å¿—è®°å½•
    caps = DesiredCapabilities.CHROME
    caps['goog:loggingPrefs'] = {'performance': 'ALL'}
    
    driver = setup_driver(headless=False)
    
    # å¯ç”¨ç½‘ç»œåŸŸ
    driver.execute_cdp_cmd('Network.enable', {})
    driver.execute_cdp_cmd('Page.enable', {})
    
    print("âœ… æµè§ˆå™¨ç½‘ç»œç›‘æ§å·²å¯ç”¨")
    return driver


def capture_network_requests(driver, duration: int = 30) -> List[Dict]:
    """æ•è·ç½‘ç»œè¯·æ±‚"""
    print(f"ğŸ•·ï¸ å¼€å§‹æ•è·ç½‘ç»œè¯·æ±‚ ({duration}ç§’)...")
    
    requests_data = []
    start_time = time.time()
    
    try:
        while time.time() - start_time < duration:
            # è·å–æ€§èƒ½æ—¥å¿—
            logs = driver.get_log('performance')
            
            for log in logs:
                message = json.loads(log['message'])
                if message['message']['method'] == 'Network.responseReceived':
                    response = message['message']['params']['response']
                    request_data = {
                        'url': response['url'],
                        'status': response['status'],
                        'method': response.get('method', 'unknown'),
                        'headers': response.get('headers', {}),
                        'timing': response.get('timing', {}),
                        'timestamp': datetime.now().isoformat()
                    }
                    requests_data.append(request_data)
                    
                    # å®æ—¶æ˜¾ç¤ºæ•è·çš„è¯·æ±‚
                    if len(requests_data) % 10 == 0:
                        print(f"\rğŸ“¡ å·²æ•è· {len(requests_data)} ä¸ªç½‘ç»œè¯·æ±‚", end="", flush=True)
            
            time.sleep(0.1)
            
    except Exception as e:
        print(f"âš ï¸ ç½‘ç»œç›‘æ§å¼‚å¸¸: {e}")
    
    print(f"\nâœ… ç½‘ç»œè¯·æ±‚æ•è·å®Œæˆï¼Œå…± {len(requests_data)} ä¸ªè¯·æ±‚")
    return requests_data


def crawl_page_content(driver, url: str) -> Dict[str, Any]:
    """çˆ¬å–é¡µé¢å†…å®¹"""
    print(f"ğŸ•·ï¸ å¼€å§‹çˆ¬å–é¡µé¢: {url}")
    
    try:
        # è®¿é—®é¡µé¢
        driver.get(url)
        time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
        
        page_data = {
            'url': url,
            'title': driver.title,
            'current_url': driver.current_url,
            'page_source_length': len(driver.page_source),
            'timestamp': datetime.now().isoformat()
        }
        
        # å°è¯•è·å–ç‰¹å®šå…ƒç´ 
        try:
            # æŸ¥æ‰¾ç™»å½•ç›¸å…³å…ƒç´ 
            wait = WebDriverWait(driver, 5)
            login_elements = driver.find_elements(By.XPATH, "//*[contains(text(), 'ë¡œê·¸ì¸') or contains(text(), 'ç™»å½•') or contains(text(), 'Login')]")
            page_data['login_elements_count'] = len(login_elements)
            
            # æŸ¥æ‰¾ç”³è¯·/æŠ¥åç›¸å…³å…ƒç´ 
            apply_elements = driver.find_elements(By.XPATH, "//*[contains(text(), 'ì‹ ì²­') or contains(text(), 'ç”³è¯·') or contains(text(), 'Apply')]")
            page_data['apply_elements_count'] = len(apply_elements)
            
            # è·å–æ‰€æœ‰é“¾æ¥
            links = driver.find_elements(By.TAG_NAME, 'a')
            page_data['total_links'] = len(links)
            
            # è·å–æ‰€æœ‰æŒ‰é’®
            buttons = driver.find_elements(By.TAG_NAME, 'button')
            page_data['total_buttons'] = len(buttons)
            
        except TimeoutException:
            page_data['elements_error'] = "é¡µé¢å…ƒç´ åŠ è½½è¶…æ—¶"
        
        print(f"âœ… é¡µé¢çˆ¬å–å®Œæˆ:")
        print(f"   ğŸ“„ æ ‡é¢˜: {page_data['title']}")
        print(f"   ğŸ”— é“¾æ¥æ•°: {page_data.get('total_links', 0)}")
        print(f"   ğŸ–±ï¸ æŒ‰é’®æ•°: {page_data.get('total_buttons', 0)}")
        print(f"   ğŸ” ç™»å½•å…ƒç´ : {page_data.get('login_elements_count', 0)}")
        print(f"   ğŸ“ ç”³è¯·å…ƒç´ : {page_data.get('apply_elements_count', 0)}")
        
        return page_data
        
    except Exception as e:
        print(f"âŒ é¡µé¢çˆ¬å–å¤±è´¥: {e}")
        return {'url': url, 'error': str(e), 'timestamp': datetime.now().isoformat()}


def save_crawl_data(data: Dict[str, Any], filename: str = None):
    """ä¿å­˜çˆ¬å–æ•°æ®åˆ°æ–‡ä»¶"""
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"crawl_data_{timestamp}.json"
    
    filepath = project_root / "data" / filename
    filepath.parent.mkdir(exist_ok=True)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
    return filepath


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª VPNç½‘ç»œå»¶è¿Ÿã€é¡µé¢çˆ¬å–å’Œè¯·æ±‚ç›‘æ§ç»¼åˆæµ‹è¯•")
    print("=" * 70)
    
    # 1. VPNç½‘ç»œå»¶è¿Ÿæ£€æµ‹
    print("\nğŸ“¡ ç¬¬1é˜¶æ®µ: VPNç½‘ç»œå»¶è¿Ÿæ£€æµ‹")
    print("-" * 40)
    latency_stats = test_vpn_network_latency(duration=15)
    
    # 2. è®¾ç½®æµè§ˆå™¨
    print("\nğŸŒ ç¬¬2é˜¶æ®µ: å¯åŠ¨æµè§ˆå™¨")
    print("-" * 40)
    driver = None
    
    try:
        driver = setup_browser_with_network_monitoring()
        
        # 3. é¡µé¢çˆ¬å–æµ‹è¯•
        print("\nğŸ•·ï¸ ç¬¬3é˜¶æ®µ: é¡µé¢çˆ¬å–æµ‹è¯•")
        print("-" * 40)
        
        test_urls = [
            "https://www.weverse.io",
            "https://weverse.io/nct127/notice"
        ]
        
        crawl_results = []
        for url in test_urls:
            page_data = crawl_page_content(driver, url)
            crawl_results.append(page_data)
        
        # 4. ç½‘ç»œè¯·æ±‚ç›‘æ§
        print("\nğŸ“¡ ç¬¬4é˜¶æ®µ: ç½‘ç»œè¯·æ±‚ç›‘æ§")
        print("-" * 40)
        print("ğŸ”„ è®¿é—®Weverseä¸»é¡µè¿›è¡Œç½‘ç»œç›‘æ§...")
        
        # è®¿é—®é¡µé¢å¹¶ç›‘æ§ç½‘ç»œè¯·æ±‚
        driver.get("https://www.weverse.io")
        network_requests = capture_network_requests(driver, duration=20)
        
        # 5. æ•´åˆæ‰€æœ‰æ•°æ®
        print("\nğŸ’¾ ç¬¬5é˜¶æ®µ: æ•°æ®æ•´åˆä¿å­˜")
        print("-" * 40)
        
        comprehensive_data = {
            'test_info': {
                'timestamp': datetime.now().isoformat(),
                'test_duration_seconds': 60,
                'vpn_status': 'active'
            },
            'network_latency': latency_stats,
            'page_crawl_results': crawl_results,
            'network_requests': network_requests,
            'summary': {
                'total_pages_crawled': len(crawl_results),
                'total_network_requests': len(network_requests),
                'avg_latency_ms': latency_stats['avg_ms'],
                'recommended_advance_ms': latency_stats['recommended_advance_ms']
            }
        }
        
        # ä¿å­˜æ•°æ®
        saved_file = save_crawl_data(comprehensive_data)
        
        # 6. ç»“æœåˆ†æ
        print("\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 50)
        print(f"âœ… VPNå»¶è¿Ÿæ£€æµ‹: å¹³å‡ {latency_stats['avg_ms']:.1f}ms")
        print(f"âœ… é¡µé¢çˆ¬å–: {len(crawl_results)} ä¸ªé¡µé¢")
        print(f"âœ… ç½‘ç»œè¯·æ±‚: {len(network_requests)} ä¸ªè¯·æ±‚")
        print(f"âœ… æ¨èæå‰æ—¶é—´: {latency_stats['recommended_advance_ms']:.1f}ms")
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {saved_file.name}")
        
        # åˆ†æä½ æä¾›çš„å»¶è¿Ÿæ•°æ®
        print(f"\nğŸ” åŸºäºä½ çš„å®é™…æ•°æ®åˆ†æ:")
        print(f"   - ä½ çš„å»¶è¿ŸèŒƒå›´: 36ms - 1.32s")
        print(f"   - æ£€æµ‹åˆ°çš„å»¶è¿Ÿ: {latency_stats['min_ms']:.0f}ms - {latency_stats['max_ms']:.0f}ms")
        if latency_stats['max_ms'] > 1000:
            print(f"   âš ï¸  æ£€æµ‹åˆ°é«˜å»¶è¿Ÿï¼Œå»ºè®®æå‰æ—¶é—´: {latency_stats['recommended_advance_ms']:.0f}ms")
        else:
            print(f"   âœ… ç½‘ç»œçŠ¶å†µè‰¯å¥½ï¼Œæå‰æ—¶é—´: {latency_stats['recommended_advance_ms']:.0f}ms")
        
        print("\nğŸŠ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("ğŸ“‹ ç°åœ¨ä½ å¯ä»¥æŸ¥çœ‹ä¿å­˜çš„æ•°æ®æ–‡ä»¶äº†è§£è¯¦ç»†ä¿¡æ¯")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        
    finally:
        if driver:
            print("\nğŸ”„ å…³é—­æµè§ˆå™¨...")
            driver.quit()
            print("âœ… æµè§ˆå™¨å·²å…³é—­")


if __name__ == "__main__":
    main() 