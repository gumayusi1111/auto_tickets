#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_nearby_servers.py
æµ‹è¯•é™„è¿‘å…¬å¸/æœåŠ¡å™¨çš„å»¶è¿Ÿï¼Œè·å–æ›´å‡†ç¡®çš„ç½‘ç»œæ€§èƒ½æ•°æ®
"""

import time
import requests
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed

class NearbyServerTester:
    def __init__(self):
        # äºšæ´²åœ°åŒºçš„ä¸»è¦å…¬å¸/æœåŠ¡å™¨
        self.test_targets = [
            # éŸ©å›½å…¬å¸
            "https://www.samsung.com",           # ä¸‰æ˜Ÿ
            "https://www.lge.com",               # LG
            "https://www.kakao.com",             # ì¹´ì¹´ì˜¤
            "https://www.nexon.com",             # æ¸¸æˆå…¬å¸
            
            # æ—¥æœ¬å…¬å¸ï¼ˆåœ°ç†ä½ç½®ç›¸è¿‘ï¼‰
            "https://www.sony.com",              # ç´¢å°¼
            "https://www.nintendo.com",          # ä»»å¤©å ‚
            "https://www.rakuten.com",           # ä¹å¤©
            
            # é¦™æ¸¯/å°æ¹¾åœ°åŒº
            "https://www.hkt.com",               # é¦™æ¸¯ç”µè®¯
            "https://www.pchome.com.tw",         # å°æ¹¾PChome
            "https://www.momo.com.tw",           # å°æ¹¾momo
            
            # ä¸­å›½å¤§é™†å…¬å¸ï¼ˆå¯¹æ¯”ï¼‰
            "https://www.tencent.com",           # è…¾è®¯
            "https://www.alibaba.com",           # é˜¿é‡Œå·´å·´
            "https://www.baidu.com",             # ç™¾åº¦
        ]
    
    def test_server_latency(self, url: str, timeout: int = 3) -> float:
        """æµ‹è¯•å•ä¸ªæœåŠ¡å™¨å»¶è¿Ÿ"""
        try:
            start_time = time.perf_counter()
            response = requests.head(url, timeout=timeout, headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }, allow_redirects=False)
            end_time = time.perf_counter()
            
            # æ¥å—æ›´å¤šçŠ¶æ€ç 
            if response.status_code in [200, 301, 302, 404, 403, 503]:
                return (end_time - start_time) * 1000
            else:
                return None
        except:
            return None
    
    def test_multiple_samples(self, url: str, samples: int = 3) -> list:
        """å¯¹å•ä¸ªURLè¿›è¡Œå¤šæ¬¡é‡‡æ ·"""
        latencies = []
        for _ in range(samples):
            latency = self.test_server_latency(url)
            if latency is not None:
                latencies.append(latency)
            time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«
        return latencies
    
    def analyze_regional_latency(self):
        """åˆ†æå„åœ°åŒºå»¶è¿Ÿæƒ…å†µ"""
        print("ğŸŒ æµ‹è¯•äºšæ´²åœ°åŒºä¸»è¦å…¬å¸æœåŠ¡å™¨å»¶è¿Ÿ")
        print("=" * 60)
        
        regions = {
            'éŸ©å›½': [
                "https://www.samsung.com",
                "https://www.lge.com",
                "https://www.kakao.com",
                "https://www.nexon.com"
            ],
            'æ—¥æœ¬': [
                "https://www.sony.com",
                "https://www.nintendo.com",
                "https://www.rakuten.com"
            ],
            'é¦™æ¸¯/å°æ¹¾': [
                "https://www.hkt.com",
                "https://www.pchome.com.tw",
                "https://www.momo.com.tw"
            ],
            'ä¸­å›½å¤§é™†': [
                "https://www.tencent.com",
                "https://www.alibaba.com",
                "https://www.baidu.com"
            ]
        }
        
        regional_results = {}
        
        for region, urls in regions.items():
            print(f"\nğŸ” æµ‹è¯• {region} åœ°åŒº:")
            region_latencies = []
            
            for url in urls:
                company_name = self._extract_company_name(url)
                latencies = self.test_multiple_samples(url, 3)
                
                if latencies:
                    avg_latency = statistics.mean(latencies)
                    region_latencies.extend(latencies)
                    print(f"   {company_name:12} - {avg_latency:6.1f}ms (æ ·æœ¬: {len(latencies)})")
                else:
                    print(f"   {company_name:12} - è¿æ¥å¤±è´¥")
            
            if region_latencies:
                region_avg = statistics.mean(region_latencies)
                region_min = min(region_latencies)
                region_max = max(region_latencies)
                regional_results[region] = {
                    'avg': region_avg,
                    'min': region_min,
                    'max': region_max,
                    'samples': len(region_latencies)
                }
                print(f"   ğŸ“Š {region} å¹³å‡: {region_avg:.1f}ms (èŒƒå›´: {region_min:.1f}-{region_max:.1f}ms)")
        
        return regional_results
    
    def _extract_company_name(self, url: str) -> str:
        """ä»URLæå–å…¬å¸åç§°"""
        domain_to_name = {
            'samsung.com': 'Samsung',
            'lge.com': 'LG',
            'kakao.com': 'Kakao',
            'nexon.com': 'Nexon',
            'sony.com': 'Sony',
            'nintendo.com': 'Nintendo',
            'rakuten.com': 'Rakuten',
            'hkt.com': 'HKT',
            'pchome.com.tw': 'PChome',
            'momo.com.tw': 'Momo',
            'tencent.com': 'Tencent',
            'alibaba.com': 'Alibaba',
            'baidu.com': 'Baidu'
        }
        
        for domain, name in domain_to_name.items():
            if domain in url:
                return name
        return url.split('//')[1].split('/')[0]
    
    def estimate_korea_latency(self, regional_results: dict) -> dict:
        """åŸºäºæµ‹è¯•ç»“æœä¼°ç®—åˆ°éŸ©å›½çš„åˆç†å»¶è¿Ÿ"""
        print(f"\nğŸ¯ åŸºäºæµ‹è¯•ç»“æœä¼°ç®—åˆ°éŸ©å›½æœåŠ¡å™¨çš„å»¶è¿Ÿ:")
        
        estimates = {}
        
        # å¦‚æœæœ‰éŸ©å›½æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
        if 'éŸ©å›½' in regional_results:
            korea_avg = regional_results['éŸ©å›½']['avg']
            estimates['direct_korea'] = korea_avg
            print(f"   ç›´æ¥æµ‹è¯•éŸ©å›½: {korea_avg:.1f}ms")
        
        # åŸºäºæ—¥æœ¬æ•°æ®ä¼°ç®—ï¼ˆåœ°ç†ä½ç½®ç›¸è¿‘ï¼‰
        if 'æ—¥æœ¬' in regional_results:
            japan_avg = regional_results['æ—¥æœ¬']['avg']
            # å°æ¹¾åˆ°éŸ©å›½æ¯”åˆ°æ—¥æœ¬ç¨å¾®è¿œä¸€ç‚¹ï¼Œ+10-20ms
            estimated_korea = japan_avg + 15
            estimates['japan_based'] = estimated_korea
            print(f"   åŸºäºæ—¥æœ¬æ•°æ®: {japan_avg:.1f}ms â†’ éŸ©å›½çº¦ {estimated_korea:.1f}ms")
        
        # åŸºäºé¦™æ¸¯/å°æ¹¾æ•°æ®ä¼°ç®—
        if 'é¦™æ¸¯/å°æ¹¾' in regional_results:
            hk_tw_avg = regional_results['é¦™æ¸¯/å°æ¹¾']['avg']
            # å°æ¹¾å†…éƒ¨åˆ°éŸ©å›½ï¼Œ+20-40ms
            estimated_korea = hk_tw_avg + 30
            estimates['hk_tw_based'] = estimated_korea
            print(f"   åŸºäºé¦™æ¸¯å°æ¹¾: {hk_tw_avg:.1f}ms â†’ éŸ©å›½çº¦ {estimated_korea:.1f}ms")
        
        # è®¡ç®—æœ€ç»ˆæ¨èå€¼
        if estimates:
            final_estimate = statistics.mean(estimates.values())
            print(f"   ğŸ“Š ç»¼åˆä¼°ç®—: {final_estimate:.1f}ms")
            
            # è½¬æ¢ä¸ºVPNä¼˜åŒ–å™¨æ ¼å¼
            return {
                'estimated_korea_latency': final_estimate,
                'confidence': 'high' if len(estimates) >= 2 else 'medium',
                'recommended_preclick_ms': min(final_estimate + 20, 150),  # åŠ å®‰å…¨è¾¹é™…ï¼Œä½†ä¸è¶…è¿‡150ms
                'data_sources': list(estimates.keys())
            }
        else:
            print("   âš ï¸ æ— æ³•è·å¾—å¯é ä¼°ç®—ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return {
                'estimated_korea_latency': 80,
                'confidence': 'low',
                'recommended_preclick_ms': 100,
                'data_sources': ['default']
            }
    
    def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("ğŸš€ äºšæ´²åœ°åŒºæœåŠ¡å™¨å»¶è¿Ÿç»¼åˆæµ‹è¯•")
        print("ğŸ“ å½“å‰ä½ç½®: å°æ¹¾")
        print("ğŸ¯ ç›®æ ‡: ä¼°ç®—åˆ°éŸ©å›½çš„çœŸå®å»¶è¿Ÿ\n")
        
        # åˆ†æå„åœ°åŒºå»¶è¿Ÿ
        regional_results = self.analyze_regional_latency()
        
        # ä¼°ç®—éŸ©å›½å»¶è¿Ÿ
        korea_estimate = self.estimate_korea_latency(regional_results)
        
        # è¾“å‡ºæœ€ç»ˆå»ºè®®
        print(f"\nâœ… æµ‹è¯•å®Œæˆ - VPNä¼˜åŒ–å»ºè®®:")
        print(f"   ğŸ‡°ğŸ‡· ä¼°ç®—éŸ©å›½å»¶è¿Ÿ: {korea_estimate['estimated_korea_latency']:.1f}ms")
        print(f"   âš¡ å»ºè®®æå‰ç‚¹å‡»: {korea_estimate['recommended_preclick_ms']:.1f}ms")
        print(f"   ğŸ“Š æ•°æ®å¯ä¿¡åº¦: {korea_estimate['confidence']}")
        print(f"   ğŸ“ˆ æ•°æ®æ¥æº: {', '.join(korea_estimate['data_sources'])}")
        
        return korea_estimate


def main():
    tester = NearbyServerTester()
    result = tester.run_comprehensive_test()
    
    # ä¸å½“å‰VPNä¼˜åŒ–å™¨å¯¹æ¯”
    print(f"\nğŸ“‹ å¯¹æ¯”å½“å‰VPNä¼˜åŒ–å™¨:")
    print(f"   å½“å‰æ£€æµ‹ç»“æœ: ~900ms (å¼‚å¸¸)")
    print(f"   å®é™…æµ‹è¯•ä¼°ç®—: {result['estimated_korea_latency']:.1f}ms (åˆç†)")
    print(f"   å»ºè®®ä½¿ç”¨: {result['recommended_preclick_ms']:.1f}ms æå‰ç‚¹å‡»")


if __name__ == "__main__":
    main() 